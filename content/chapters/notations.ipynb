{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adjustable-trace",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# Notationen\n",
    "\n",
    "In diesem Buch verwenden wir viele Mathematische Notation. Hier sind noch einmal die wichtigsten zum Nachschlagen also Tabelle. \n",
    "\n",
    "| Notation | Definition |\n",
    "|----------|------------|\n",
    "| $\\mathbb{R}$ | Die reellen Zahlen, also mehr oder weniger beliebige numerische Werte. |\n",
    "| $\\mathbb{N}$ | Die natürlichen Zahlen, also alle ganzen Zahlen die größer null sind.  |\n",
    "| $O$ | Objektraum, also die Menge der Objekte aus der realen Welt. |\n",
    "| $\\phi$ | Feature map, also eine Abbildung die definiert wie Merkmale für Objekte berechnet werden. |\n",
    "| $\\mathcal{F}$ | Merkmalsraum (engl. feature space), also die Dimension und die möglichen Werte der Merkmale. Häufig ist dies der $\\mathbb{R}^d$, also die $d$-dimensionalen reellen Zahlen. In diesem Fall gibt es $d \\in \\mathbb{N}$ Merkmale. |\n",
    "| $X$ (Clustering, Klassifikation, Regression) |  Instanzen von Objekten im Merkmalsraum. Je nach Kontext ist $X$ entweder eine Menge von Instanzen $X = \\{x_1, ..., x_n\\} \\subseteq \\mathcal{F}$ oder eine Zufallsvariable, so dass die Instanzen Realisierungen dieser Zufallsvariablen sind. |\n",
    "| $Y$ (Klassifikation, Regression) | Wert von Interesse, also die Klasse oder die abhängige Variable. Wie $X$ wird $Y$ auch entweder als Menge $Y= \\{y_1, ..., y_n\\}$ oder als Zufallsvariable definiert. |\n",
    "| $I$ | Endliche Menge von Gegenständen  \\{i_1, ..., i_m\\}.\n",
    "| $T$ | Endliche Menge von Transaktionen $T=\\{t_1, ..., t_n\\}$, wobei $t_i \\subseteq I$ für $i=1, ..., n$. |\n",
    "| $X$ (Assoziationsregeln) | Bedingung (engl. antecedent) einer Assoziationsregel. |\n",
    "| $Y$ (Assoziationsregeln) | Folgerung (engl. consequent) einer Assoziationsregel. |\n",
    "| $X \\Rightarrow Y$ | Assoziationsregel, wobei $X$ die Bedingung und $Y$ die Folgerung ist. |\n",
    "| ${n \\choose k}$ | Binomialkoeffizient ${n \\choose k} = \\frac{n!}{(n-k)!k!}$. |\n",
    "| $\\mathcal{P}(I)$ | Die Potenzmenge einer endlichen Menge $I$. |\n",
    "| $\\vert \\cdot \\vert$ | Die Kardinalität einer Menge, zum Beispiel $\\vert X \\vert$ für die Anzahl der Elemente der Menge $X$ |\n",
    "| $d(x,y)$ | Distanz zwischen zwei Vektoren $x$ und $y$, zum Beispiel die Euklidische Distanz, die Manhattan Distanz oder die Chebyshev Distanz. |\n",
    "| $argmin_{i=1,...,k} f(i)$ | Der Wert $i$ für den die Funktion $f$ minimiert wird. |\n",
    "| $argmin_{i \\in \\{1, ..., k\\}} f(i)$ | Andere Schreibweise für $argmin_{i=1,...,k} f(i)$. |\n",
    "| $\\min_{i=1,...,k} f(i)$ | Das Minimum der Funktion $f$ über die verschiedenen Werte von $i$. |\n",
    "| $\\min_{i \\in \\{1, ..., k\\}} f(i)$ | Andere Schreibweise für $\\min_{i=1, ..., k}$. |\n",
    "| $argmax$ | Siehe $argmin$. |\n",
    "| $\\max$ | Siehe $\\min$. |\n",
    "| $\\sim$ | Definiert die Verteilung einer Zufallsvariable. Wir schreiben $X \\sim (\\mu, \\sigma)$ um zu definieren das $X$ normalverteilt mit dem Mittelwert $ \\mu$ und der Standardabweichung $\\sigma$ ist.|\n",
    "| $C$ (Klassifikation) | Menge der Klassen. |\n",
    "| $C$ (Clustering) | Beschreibung der Cluster. |\n",
    "| $h$ | Hypothese, Konzept, Klassifikator, Klassifikationsmodell. |\n",
    "| $h^*$ | Zielkonzept. |\n",
    "| $h'_c$ | Score einer Hypothese für die Klasse $c$. |\n",
    "| $P(X=x)$ | Wahrscheinlichkeit, dass die Zufallsvariable $X$ den Wert $x$ annimmt. |\n",
    "| $p(x)$ | Kurzform für $p(x) = P(X=x)$ bei eine Zufallsvariable $x$. |\n",
    "| $P(X \\vert Y)$ | Bedingte Wahrscheinlichkeit einer Zufallsvariablen $X$ gegeben eine andere Zufallsvariable $Y$. | \n",
    "| $H(X)$ | Entropie einer Zufallsvariablen $X$. |\n",
    "| $H(X \\vert Y)$ | Bedingte Entropie der Zufallsvariablen $X$ gegeben der Zufallsvariable $Y$. |\n",
    "| $I(X; Y)$ | Informationsgewinn (engl. information gain) für $X$, bzw. $Y$, wenn die andere Variable bekannt ist. Auch bekannt als gemeinsame Information (engl. mutual information). |\n",
    "| $e_x$ | Residuen einer Regression. |\n",
    "| $x_t$ | Werte einer Zeitreihe $\\{x_1, ..., x_T\\} = \\{x_t\\}_{t=1}^T$. |\n",
    "| $T_t$ | Trend einer Zeitreihe. |\n",
    "| $S_t$ | Saisonalität einer Zeitreihe. |\n",
    "| $R_t$ | Autoregressiver Teil einer Zeitreihe. |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
