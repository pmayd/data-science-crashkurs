
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. Big Data und Data Science &#8212; Einführung in Data Science</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e7340bb3dbd8dde6db86f25597f54a1b.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. Der Prozess von Data Science Projekten" href="kapitel_02.html" />
    <link rel="prev" title="Vorwort" href="../vorwort.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Einführung in Data Science</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../vorwort.html">
   Vorwort
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Kapitel
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1. Big Data und Data Science
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kapitel_02.html">
   2. Der Prozess von Data Science Projekten
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Übungen
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../exercises/uebung_01.html">
   Übung 1
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/chapters/kapitel_01.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/sherbold/einfuehrung-in-data-science"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/sherbold/einfuehrung-in-data-science/main?urlpath=tree/content/chapters/kapitel_01.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#einfuhrung-in-big-data">
   1.1. Einführung in Big Data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#volumen">
     1.1.1. Volumen
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#velocity-tempo">
     1.1.2. Velocity / Tempo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vielfalt-variety">
     1.1.3. Vielfalt / Variety
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#innovative-informationsverarbeitungsmethoden">
     1.1.4. Innovative Informationsverarbeitungsmethoden
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#wissen-generieren-entscheidungen-treffen-prozesse-automatisieren">
     1.1.5. Wissen generieren, Entscheidungen treffen, Prozesse automatisieren.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#noch-mehr-vs">
     1.1.6. Noch mehr Vs
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-science">
   1.2. Data Science
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#was-gehort-zu-data-science">
     1.2.1. Was gehört zu Data Science?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#beispielanwendungen">
     1.2.2. Beispielanwendungen
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fahigkeiten-von-data-scientists">
   1.3. Fähigkeiten von Data Scientists
  </a>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="big-data-und-data-science">
<h1><span class="section-number">1. </span>Big Data und Data Science<a class="headerlink" href="#big-data-und-data-science" title="Permalink to this headline">¶</a></h1>
<div class="section" id="einfuhrung-in-big-data">
<h2><span class="section-number">1.1. </span>Einführung in Big Data<a class="headerlink" href="#einfuhrung-in-big-data" title="Permalink to this headline">¶</a></h2>
<p>Den Begriff <em>Big Data</em> gibt es jetzt bereits seit einigen Jahren und der ursprüngliche mit diesem Thema verbundene Hype ist längst Vergangenheit. Stattdessen gibt es neue Buzzwörter, wie das <em>Internet der Dinge</em> (engl. Internet of Things), die <em>Künstliche Intelligenz</em> (engl. Artificial Intelligence), und hierbei insbesondere auch die <em>tiefen neuronalen Netze</em> (engl. Deep Neural Network, Deep Learning). Nichtsdestotrotz ist Big Data mit diesen neuen Themen eng verbunden und häufig eine Voraussetzung  oder zumindest verwandte Technologie.</p>
<p>Trotz der anhaltenden Relevanz des Themas, gibt es dennoch kein häufig kein gutes Verständnis für den Unterschied zwischen einfach nur Daten und Big Data. Ein gutes Verständnis der Besonderheiten und Eigenschaften von Big Data und von den damit verbundenen Implikationen und Problemen ist jedoch zwingend Notwendig, wenn man auf Big Data aufbauende Technologien in Projekten einsetzen will. Der Grund für Missverständnisse rund um den Begriff Big Data ist einfach: Wir denken intuitiv an “große Datenmengen”, also einfach nur an Daten mit einem hohen Volumen. Eine derart vereinfachte Begriffsdefinition ignoriert jedoch wesentliche Aspekte von Big Data. Backups sind ein gutes Beispiel für große Datenmengen, die nicht Big Data sind. In modernen Rechenzentren werden Backups auf Hintergrundspeichern mit einer hoher Bitstabilität, aber auch hoher Latenz gespeichert. Dort lagern häufig riesige Datenmengen, einzig und allein mit der Hoffnung, nie gebraucht zu werden, bevor sie gelöscht oder überschrieben werden. Es gibt noch einen weiteren Grund, warum es unpraktisch ist, Big Data nur über das Datenvolumen zu definieren: Wir müssten die Definition ständig anpassen, da sowohl die Speicherkapazitäten, Rechenkraft, und der Arbeitsspeicher stetig wachsen.</p>
<p>Eine bessere und allgemein akzeptierte Definition für Big Data basiert auf den <em>drei Vs</em> <a class="footnote-reference brackets" href="#gartner" id="id1">1</a>.</p>
<blockquote>
<div><p><strong>Definition von Big Data:</strong></p>
<p>Als Big Data bezeichnet man Daten die ein hohes <em>Volumen</em>, ein hohes Tempo (engl. <em>velocity</em>), und eine hohe <em>Vielfalt</em> (engl. <em>variety</em>) haben, so dass man kosteneffiziente und innovative Informationsverarbeitungsmethoden benötigt um Wissen zu generieren, Entscheidungen zu treffen oder Prozesse zu automatisieren.</p>
</div></blockquote>
<p>Zum besseren Verständnis, zerlegen wir nun diese Definition in ihre Einzelteile und betrachten diese genauer. Hierbei wird klar werden, warum Big Data mehr ist, als nur Datenvolumen.</p>
<div class="section" id="volumen">
<h3><span class="section-number">1.1.1. </span>Volumen<a class="headerlink" href="#volumen" title="Permalink to this headline">¶</a></h3>
<p>Auch wenn das Datenvolumen nicht der einzig wichtige Faktor ist, ist es nichtsdestotrotz entscheidend. Nicht umsonst heißt es Big Data. Das keine bestimmte Datengröße das Kriterium sein kann, wird schon klar wenn man sich überlegt, dass Google die Forschungsarbeit in der Map/Reduce vorgestellt wurde <a class="footnote-reference brackets" href="#mapreducepaper" id="id2">2</a> bereits 2006 publiziert hat. Zu diesem Zeitpunkt war ein Terabyte noch eine sehr großes Datenvolumen. Im Jahr 2021 ist dies lediglich die Festplattengröße des Laptops, mit dem dieses Buch geschrieben wurde. Ein weiteres Beispiel ist das Wachstum des Datenvolumens, welches sich im Internet jährlich bewegt (<a class="reference internal" href="#fig-webtraffic"><span class="std std-numref">Fig. 1.1</span></a>).</p>
<div class="figure align-default" id="fig-webtraffic">
<a class="reference internal image-reference" href="../_images/webtraffic.png"><img alt="../_images/webtraffic.png" src="../_images/webtraffic.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-number">Fig. 1.1 </span><span class="caption-text">Wachstum des Datenvolumens des Internetverkehrs</span><a class="headerlink" href="#fig-webtraffic" title="Permalink to this image">¶</a></p>
</div>
<p>Eine vereinfachte Richtlinie für das Datenvolumen, dass Big Data haben muss ist, dass es mehr Daten sein müssen, als in den Arbeitsspeicher moderner Server passen. Besser ist es jedoch, wenn man sich einfach folgende Frage stellt, ob man es sich leisten, die Daten (oft) zu kopieren, insbesondere auch über Netzwerkverbindungen. Ist dies nicht mehr der Fall, handelt es sich vermutlich um genug Daten, um von Big Data zu sprechen. In extremen Fällen sind die Daten sogar so groß, dass man sie gar nicht über das Netzwerk kopieren kann. Stattdessen nutzt man das <em>Sneaker Net</em> <a class="footnote-reference brackets" href="#sneakernet" id="id3">3</a>: Die Daten werden direkt auf Festplatten verschickt. Vom Datendurchsatz ist eine mit Festplatten beladenes Transportflugzeug unschlagbar. Die Latenz lässt jedoch zu wünschen übrig. Ein Beispiel für eine Anwendung, die ohne das Sneaker Net nicht geklappt hätte, ist die Erstellung des ersten Bilds von einem Schwarzen Loch <a class="footnote-reference brackets" href="#blackhole" id="id4">4</a>.</p>
</div>
<div class="section" id="velocity-tempo">
<h3><span class="section-number">1.1.2. </span>Velocity / Tempo<a class="headerlink" href="#velocity-tempo" title="Permalink to this headline">¶</a></h3>
<p>Die Velocity ist das <em>Tempo</em>, mit dem neue Daten generiert, verarbeitet, und/oder ausgewertet werden müssen. Es gibt viele Beispiele für Daten die ein hohes Tempo haben, zum Beispiel die durch Sensoren wie LIDAR und Kameras erfassten Daten von autonomen Fahrzeugen. Derartige Daten können in kürzester Zeit ein sehr hohes Volumen erreichen. Die Firma Waymo hat zum Beispiel einen zwei Terabyte großen Datensatz,  der während elf Fahrstunden gesammelt wurde, veröffentlich <a class="footnote-reference brackets" href="#waymo" id="id5">5</a>. Daten die mehr oder weniger kontinuierlich in hohem Tempo generiert werden, nennt man auch <em>Streamingdaten</em>.</p>
<p>Eine besondere Schwierigkeit beim Umgang mit Streamingdaten ist das diese oft in nahezu Realzeit verarbeitet werden müssen. Beim autonomen  Fahren ist dies sofort klar, schon alleine wegen den Implikationen für die Sicherheit. Doch das gilt auch für viele andere Anwendungen, zum Beispiel dem sortieren eines Nachrichtenstreams in sozialen Netzwerken. Hier kommt zwar niemand zu schaden, die Nutzer würden einen Dienst aber schnell verlassen, wenn die Ladezeiten zu lang sind. Entsprechend müssen beim Umgang mit Streamingdaten in der Regel zwei Anforderungen gleichzeitig erfüllt werden: Daten müssen sehr schnell empfangen werden und dürfen dann auch nicht lange in einem Zwischenspeicher landen, sondern müssen auch sofort verarbeitet und ausgewertet werden. Hierdurch ergibt sich eine Art inverse Korrelation zwischen dem Tempo und dem Datenvolumen: Je höher das Tempo, desto weniger Daten reichen, um Daten zu Big Data werden zu lassen. Oder am Beispiel: Ein Gigabyte pro Tag zu verarbeiten ist einfacher, als ein Gigabyte pro Sekunde.</p>
</div>
<div class="section" id="vielfalt-variety">
<h3><span class="section-number">1.1.3. </span>Vielfalt / Variety<a class="headerlink" href="#vielfalt-variety" title="Permalink to this headline">¶</a></h3>
<p>Die Vielfalt der Daten ist der dritte große Aspekt von Big Data. Mittlerweile ist die Analyse von Bildern, Videos, und Texten zu einer relativ normalen Anwendung geworden. Dies war jedoch noch nicht in der Form der Fall, als der Begriff Big Data geprägt wurde. Im Zeitraum um die Jahrtausendwende lagen die Daten, die Analysiert werden sollten, üblicherweise strukturiert vor, zum Beispiel in relationalen Datenbanken. Die Daten waren üblicherweise entweder numerisch oder in feste Kategorien eingeteilt. Das änderte sich im Laufe der 00er Jahre, dadurch dass das Internet allgegenwärtig wurde und wie immer mehr Computertechnik in unseren Alltag übernommen haben, zum Beispiel in Form von Smartphones. Hier entstanden Daten eher auf unstrukturierte Weise, zum Beispiel in Form von Webseiten die ad-hoc von Nutzern erstellt wurden. Es ist daher kein Zufall, dass Google den Begriff Big Data und die damit verbundenen Technologien mitgeprägt hat: Die Indizierung des stetig wachsenden und komplexer werdenen Internets  hat sie quasi dazu gezwungen, die Techniken die es gab rapide weiter zu entwickeln. Hierbei mussten nicht nur immer größere Datenmengen verarbeitet werden, sondern vor allem eine Vielfalt von Datenformaten, insbesondere Text und Bilddaten, später auch Videodaten.</p>
<p>Insgesamt gibt es viel mehr unstrukturierte Daten als strukturierte Daten. Dies wird üblicherweise als Pyramide dargestellt (<a class="reference internal" href="#fig-structures"><span class="std std-numref">Fig. 1.2</span></a>), in der zwischen <em>unstrukturierten</em>, <em>quasistrukturierten</em>, <em>semistrukturierten</em>, und <em>strukturierten</em> Daten unterschieden wird.</p>
<div class="figure align-default" id="fig-structures">
<a class="reference internal image-reference" href="../_images/data_structures.png"><img alt="../_images/data_structures.png" src="../_images/data_structures.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-number">Fig. 1.2 </span><span class="caption-text">Wachstum des Datenvolumens des Internetverkehrs</span><a class="headerlink" href="#fig-structures" title="Permalink to this image">¶</a></p>
</div>
<p>An der Spitze der Pyramide sind die strukturierten Daten, zum Beispiel Tabellen in relationalen Datenbanken, <em>Comma Separated Value</em> (CSV) Dateien, und ähnliches. Strukturierte Daten kann man im Normalfall direkt in ein Analysetool laden, ohne das Vorverarbeitungsschritte notwendig sind. Die Vorverarbeitung beschränkt sich daher bei strukturierten Daten höchstens auf Aufgaben wie das säubern der Daten, zum Beispiel um ungültige Datenpunkte oder Ausreißer zu filtern.</p>
<p>Als nächstes kommen die semistrukturierten Daten, zum Beispiel XML oder JSON. Der Hauptunterschied zwischen strukturierten und semistrukturierten Daten ist die Flexibilität der Datenformate. Bei strukturierten Daten ist zum Beispiel der in der Regel der Typ einer Spalte fest definiert. Dies ist bei semistrukturierten Daten anders: hier gibts es häufig verschachtelte Strukturen, die man für die Analyse erst aufbrechen muss. Außerdem gibt es häufig optionale Felder, was die Verarbeitung komplizierter werden lassen kann. Dennoch kann man mit semistrukturierten Daten in der Regel einfach arbeiten, da diese auch ohne großen Aufwand in viele Analyseumgebungen importiert werden können.</p>
<p>Im Allgemeinen haben die strukturierten und semistrukturierten Daten es also gemeinsam, dass es feste Datenformate und/oder Anfragesprachen gibt, mit denen man einfach die benötigten Informationen extrahieren und laden kann. Dies ist in den beiden unteren Ebenen der Pyramide nicht mehr der Fall. Quasistrukturierte Daten haben zwar eine fest definierte Struktur, es wird aber ein gewisser Aufwand benötigt, um an die benötigen Informationen zu kommen. Als Beispiel betrachten wir die Ausgabe das <code class="docutils literal notranslate"><span class="pre">ls</span> <span class="pre">-l</span></code> Befehls, mit dem man sich in einem Linuxterminal die Dateien in einem Ordner anzeigen lassen kann.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">ls</span> -l
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>total 52
drwxr-xr-x 1 sherbold sherbold   512 Feb 25 17:53 <span class=" -Color -Color-Bold -Color-Bold-Blue">images</span>/
-rw-r--r-- 1 sherbold sherbold 47686 Feb 25 18:45 kapitel_01.ipynb
-rw-r--r-- 1 sherbold sherbold   621 Feb 12 19:48 kapitel_02.ipynb
</pre></div>
</div>
</div>
</div>
<p>Man sieht eine klare Struktur in den Daten: Die meisten Zeilen beinhalten die Benutzerrechte, gefolgt von der Anzahl der Symlinks auf die Datei, dem Benutzer und der Gruppe, welche die Datei besitzen, die Dateigröße, das Datum der letzten Änderung, und zuletzt der Name. Diese Struktur kann man Nutzen um einen Parser der die Daten einliest zu schreiben, zum Beispiel mit Hilfe von einem regulären Ausdruck. Wir können also eine Struktur über quasi-strukturierte legen, in dem wir die Struktur durch einen Parser selbst definieren. Dies ist zwar mehr Aufwand, als bei strukturierten und semistrukturierten Daten, aber man kommt trotzdem zuverlässig an die benötigten Informationen. Trotzdem kann es sehr leicht passieren, dass sich die Struktur ändert und der selbst geschrieben Parser nicht mehr funktioniert. Daher ist das lesen von quasistrukturierten Daten fehleranfällig, da man einfach Sonderfälle übersieht oder sich das Datenformat ändern kann. Man sollte also den oft signifikanten Wartungsaufwand bei der Verarbeitung von quasistrukturierten Daten einplanen, wenn man dies im produktivbetrieb benötigt.</p>
<p>Die unstrukturierten Daten sind auf der untersten Ebene der Pyramide. Hier befindet sich der Großteil der Daten: Bilder, Videos, und Text. Die Herausforderung bei diesen Daten ist es, eine Struktur zu bestimmen, die man später verarbeiten kann. Hier gibt es keine Faustformel, es hängt stattdessen von den konkreten Daten und der geplanten Anwendung ab. Hinzu kommt, das unstrukturierte Daten häufig vermischt sind. Dieses Buch ist ein gutes Beispiel: Wir haben eine Mischung aus natürlicher Sprache, Bildern, Formatinformationen (z.B. Überschriften, Listen), und Quelltext. Hierdurch wird die Verarbeitung noch komplizierter. Beispiele für die Strukturierung finden Sie an verschiedenen Stellen in diesem Buch. (TODO: Referenzen einfügen)</p>
</div>
<div class="section" id="innovative-informationsverarbeitungsmethoden">
<h3><span class="section-number">1.1.4. </span>Innovative Informationsverarbeitungsmethoden<a class="headerlink" href="#innovative-informationsverarbeitungsmethoden" title="Permalink to this headline">¶</a></h3>
<p>Auch wenn die drei <em>Vs</em> als die zentralen Eigenschaften von Big Data angesehen werden, sind die anderen Teile der Definition auch wichtig um zu verstehen das Big Data mehr ist als einfach nur viele Daten, die möglicherweise schnell generiert werden und verschiedene Formate haben. Der nächste Teil der Definition spricht von dem Bedarf an <em>innovativen Informationsverarbeitungsmethoden</em>. Das bedeutet, dass man für Big Data nicht eine einen normalen Arbeitsplatzrechner oder sogar ein traditionelles Batch System in einem Großrechner, in dem sich viele Rechenknoten einen geteilten Speicher über das Netzwerk teilen, nutzen kann. Stattdessen ist die <em>Datenlokalität</em> (engl. data locality) wichtig, da man in der Regel keine Kopien der Daten erzeugen kann, man kann die Daten also nicht einfach über das Netzwerk bewegen. Dies hat zu einer Transformation geführt, so dass es immer mehr Infrastrukturen gibt, in denen Rechenkraft und schneller verteilter Speicher direkt integriert sind. Als Big Data ein neues Konzept war, gab es solche Technologien noch nicht. Heutzutage hat man viele Möglichkeiten. Alleine bei der Apache Foundation <a class="footnote-reference brackets" href="#apache" id="id6">6</a>, gibt es unter anderem Hadoop, Spark, Storm, Kafka, Cassandra, Hive, HBase, Giraph, und vielen weitere Technologien die hochprofessionell als Open Source entwickelt werden, und von vielen Unternehmen zur Verarbeitung von Big Data eingesetzt werden.</p>
</div>
<div class="section" id="wissen-generieren-entscheidungen-treffen-prozesse-automatisieren">
<h3><span class="section-number">1.1.5. </span>Wissen generieren, Entscheidungen treffen, Prozesse automatisieren.<a class="headerlink" href="#wissen-generieren-entscheidungen-treffen-prozesse-automatisieren" title="Permalink to this headline">¶</a></h3>
<p>Der letzte Teil der Big Data Definition bedeutet das Big Data kein Selbstzweck ist. Man hat nur dann Big Data, wenn man die Daten auch zum Erreichen eines Ziels nutzt. Ziele können der reine Erkenntnisgewinn sein, die Unterstützung der Entscheidungsfindung, oder sogar die Automatisierung ganzer Geschäftsprozesse. Dieser Aspekt der Definition ist so wichtig, dass er häufig als weiteres V betrachtet wird: <em>Value</em>.</p>
</div>
<div class="section" id="noch-mehr-vs">
<h3><span class="section-number">1.1.6. </span>Noch mehr Vs<a class="headerlink" href="#noch-mehr-vs" title="Permalink to this headline">¶</a></h3>
<p>Die Definition von Gartner, die wir hier im Buch verwenden hat “nur” drei Vs. Die Definition von Big Data durch Worte die mit V anfangen ist jedoch so populär, das es verschiedene Erweiterung gibt mit bis zu 42 (!) Vs <a class="footnote-reference brackets" href="#v" id="id7">7</a>. Die 42 Vs sollte man aber eher als Satire verstehen, die zeigen soll das mehr Vs nicht immer zu einer besseren Definition führen. Nichtsdestotrotz gibt es seriöse Definition mit bis zu zehn Vs <a class="footnote-reference brackets" href="#id15" id="id8">8</a>. Ein zusätzliches V hatten wir bereits: Value, also die Wertschöpfung durch Big Data. Die Korrektheit (engl. veracity) ist ein weiteres V, was häufig als hoch relevant eingeschätzt wird. Je mehr Daten man auswertet, desto schwieriger wird es sicher zu stellen das die Daten zuverlässig sind und sich Ergebnisse reproduzieren lassen. Dies ist insbesondere dann schwer, wenn sich die Datenquellen oft ändern, zum Beispiel bei der Analyse von Nachrichten oder der sozialen Medien. Volume, Velocity, Variety, Veracity, und Value zusammen sind die fünf V Definition von Big Data, die stark verbreitet ist. Weitere Vs betrachten wir an dieser Stelle nicht mehr.</p>
</div>
</div>
<div class="section" id="data-science">
<h2><span class="section-number">1.2. </span>Data Science<a class="headerlink" href="#data-science" title="Permalink to this headline">¶</a></h2>
<p>Auch wenn der Begriff Data Science als Buzzword hoch populär ist, gibt es noch keine allgemein akzeptierte Definition. Hierfür gibt es vermutlich zwei Gründe: Erstens, ist der Begriff sehr generisch, so dass jede Verwendung von Daten, die man in irgendeiner Form als “wissenschaftlich” bezeichnen kann, als Data Science bezeichnet werden kann. Und zweitens gibt es einen großen Hype um diesen Begriff, wodurch Firmen, Fördermittelgeber, und öffentliche Institutionen mit diesem Begriff Werbung für sich betreiben wollen.</p>
<p>Aus diesem Grund können wir hier leider auch keine kurze und einprägsame Definition für diesen Begriff geben. Stattdessen betrachten wir welche Konzepte unter anderm als Data Science betrachtet werden und sehen uns Beispiele für Data Science Anwendungen an.</p>
<div class="section" id="was-gehort-zu-data-science">
<h3><span class="section-number">1.2.1. </span>Was gehört zu Data Science?<a class="headerlink" href="#was-gehort-zu-data-science" title="Permalink to this headline">¶</a></h3>
<p>Data Science kombiniert Methoden aus der Mathematik, Statistik und Informatik mit dem Ziel datengetriebene Anwendungen zu entwickeln oder wissen zu generieren. Die Wertschöpfung ist also sehr ähnlich zu Big Data. Der Hauptunterschied zwischen den Begriffen liegt auf dem Fokus auf große Datenmengen bei Big Data, der bei Data Science nicht gegeben sein muss.</p>
<p>Mathematik ist häufig das Fundament, auf dem die Datenanalyse definiert wird. Die Modelle über die Daten die erstellt werden sind im Endeffekt nichts anderes als mathematische Beschreibung von Aspekten der Daten. Man könnte also Data Science als mathematische Modellierung verstehen. Die Rolle von Mathematik ist jedoch größer als die einer “Beschreibungssprache” für Modelle. Teilgebiete der Mathematik liefern die Methoden, die man braucht um Modelle zu bestimmen.</p>
<ul class="simple">
<li><p><em>Optimierung</em> beschreibt wie man die optimale Lösung für eine Zielfunktion findet, so dass die gefundene Lösung gewisse Nebenbedingungen erfüllt. Die Zielfunktion und Nebenbedingungen werden bei Data Science häufig direkt aus den Daten bestimmt, so dass die Lösung optimal für die gegeben Daten ist.</p></li>
<li><p><em>Stochastik</em> ist ein Teilgebiet der Mathematik welches sich mit zufälligen Verhalten durch Zufallsvariablen und stochastische Prozesse befasst. Stochastik bildet daher eine wichtige Grundlage für die Theorie des maschinellen Lernens und stochastische Modelle werden häufig genutzt um Daten zu beschreiben.</p></li>
<li><p>Ohne die <em>Geometrie</em> könnte man keine Daten die räumlich Verteilt sind analysieren, zum Beispiel geographische Daten oder der 3-dimensionale Raum vor einem Fahrzeug.</p></li>
<li><p><em>Wissenschaftliches Rechnen</em> wird immer häufiger nicht nur genutzt um Daten für Analysen zu simulieren, sondern auch um Modelle über Daten durch Simulation zu bestimmen.</p></li>
</ul>
<p>Die Statistik befasst sich mit der Analyse von Daten durch Stichproben, zum Beispiel das Schätzen der den Daten Zugrunde liegenden Verteilungen, Zeitreihenanalysen, oder der Entwicklung von statistischen Tests, mit denen man auswerten kann ob Effekte zufällig oder signifikant sind.</p>
<ul class="simple">
<li><p><em>Lineare Modelle</em> sind eine vielfältig einsetzbare Methode um Daten zu Beschreiben um Zusammenhänge zu erkennen oder Trends zu erkennen.</p></li>
<li><p><em>Inferenz</em> ist ein ähnliches Verfahren, nur das Wahrscheinlichkeitsverteilungen statt linearer Modelle genutzt werden um die Daten zu beschreiben.</p></li>
<li><p><em>Zeitreihenanalyse</em> nutzt die interne Struktur von Daten, welche über die Zeit gemessen wurden. Hierbei werden zum Beispiel saisonale Effekte oder andere sich wiederholende Muster genutzt um die Struktur der Zeitreihe zu modellieren und zukünftige Werte vorherzusagen.</p></li>
</ul>
<p>Ohne die Informatik, wären die mathematischen und statistischen Verfahren nicht durch Computer ausführbar. Doch auch die theoretische Informatik liefert wichtige Grundlagen für Data Science.</p>
<ul class="simple">
<li><p><em>Datenstrukturen und Algorithmen</em> sind die Grundlage von jeder effizienten Umsetzung von Algorithmen. Ohne das Verständnis von Datenstrukturen von Bäumen, Hashmaps, und Listen, sowie von der Laufzeitkomplexität von Algorithmen, wären Datenanalysemethoden nicht skalierbar auf große Datenmenge.</p></li>
<li><p>Die <em>Informationstheorie</em> liefert das nötige Verständnis über die Entropie und gemeinsame Information von Daten und ist damit die Grundlage für viele Algorithmen des maschinellen Lernens.</p></li>
<li><p><em>Datenbanken</em> werden benötigt um Daten effizient zu Speichern und zugreifbar zu machen. SQL ist als Anfragesprache nicht nur bei relationalen Datenbanken, sondern auch bei NoSQL Datenbanken allgegenwärtig.</p></li>
<li><p><em>Paralleles und verteiltes Rechnen</em> sind notwendig um das Arbeiten mit großen Datenmengen und hoher Rechenkraft zu ermöglichen.</p></li>
<li><p>Die klassische <em>künstliche Intelligenz</em> liefert die Grundlagen für die logische Modellierung und die Definition von Regelsystemen für viele Data Science Anwendungen. In diesem Buch verwenden wir unterscheiden wir explizit zwischen künstlicher Intelligenz und maschinellem Lernen. Wir benutzt den Begriff künstliche Intelligenz um Anwendungen wie Deep Blue <a class="footnote-reference brackets" href="#deepblue" id="id9">9</a>, die regel-basierte Schachengine die als ersten Computer Gary Kasparow im besiegt hat.</p></li>
<li><p><em>Softwaretechnik</em> ist für die Operationalisierung von Anwendungen und das Management von Data Science Projekten benötigt.</p></li>
</ul>
<p>Und zuletzt gibt es natürlich noch das <em>maschinelle Lernen</em>, was häufig auch als definierender Aspekt von Data Science gesehen wird. Das maschinelle Lernen kombiniert Mathematik, Statistik, und Informatik auf geschickte Art und Weise. Je nachdem welche Methoden man betrachtet, können alle drei Disziplinen das maschinelle Lernen für sich beanspruchen. Durch maschinelles Lernen versucht man Wissen aus Daten zu gewinnen, so dass das Wissen die Daten nicht nur beschreibt, sondern auch auf weitere Daten und Anwendungen generalisiert, zum Beispiel durch Neuronale Netze, Entscheidungsbäume, und Mustererkennung.</p>
</div>
<div class="section" id="beispielanwendungen">
<h3><span class="section-number">1.2.2. </span>Beispielanwendungen<a class="headerlink" href="#beispielanwendungen" title="Permalink to this headline">¶</a></h3>
<p>So Divers wie die Grundlagen von Data Science sind auch die Anwendungen in der Forschung, Industrie, und Gesellschaft. Hier sind sechs kurze Beispiele.</p>
<ul class="simple">
<li><p><em>Alpha Go</em> ist ein Beispiel für ein intelligentes selbst-lernendes System. Vor einigen Jahren überraschte Alpha Go die Fachwelt, weil es scheinbar aus dem Nichts kam und einen der weltbesten Spieler im Go besiegte. Go gilt als besonders schwieriges Spiel, zum Beispiel im Verhältnis zu Schach, und Computer waren bis dahin gerade mal auf dem Niveau von Amateuren und stellten keine Herausforderung für professionelle Spieler dar. Alpha Go kombinierte klassische regel-basierte künstliche Intelligenz mit statistischen Monte-Carlo Simulationen und selbst-lernenden Neuronalen Netzen um dies zu erreichen.</p></li>
<li><p>Die <em>Robotik</em> nutzt maschinelles Lernen um das Robotern beizubringen sich zu bewegen. Mit der Zeit können Roboter zum Beispiel lernen durch welche Bewegungen sie das Umfallen verhindern können <a class="footnote-reference brackets" href="#robots" id="id10">10</a>.</p></li>
<li><p><em>Marketing</em> setzt auf Data Science um im Internet gezielt Werbung schalten zu können. Die dahinter liegende Industrie erwirtschaftet Milliarden, in dem Nutzern relevante Werbung basierend auf ihrem Verhalten im Internet gezeigt wird.</p></li>
<li><p>In der <em>Medizin</em> werden Daten immer häufiger genutzt um Entscheidungen zu unterstützen. IBM Watson, das erste Computerprogramm welches Menschen im Jeopardy besiegt hat <a class="footnote-reference brackets" href="#jeopardy" id="id11">11</a>, wird heutzutage zum Beispiel auch genutzt um geeignete Krebstherapien auszuwählen <a class="footnote-reference brackets" href="#cancer1" id="id12">12</a>. (Auch wenn das nicht so gut klappt, wie man es sich ursprünglich erhofft hat <a class="footnote-reference brackets" href="#cancer2" id="id13">13</a>).</p></li>
<li><p>Im <em>autonomen Fahren</em> wird maschinelles Lernen für verschiedene Aufgaben genutzt, zum Beispiel die Erkennung von Objekten, wie Verkehrsschildern, anderen Autos, oder Fußgängern.</p></li>
</ul>
</div>
</div>
<div class="section" id="fahigkeiten-von-data-scientists">
<h2><span class="section-number">1.3. </span>Fähigkeiten von Data Scientists<a class="headerlink" href="#fahigkeiten-von-data-scientists" title="Permalink to this headline">¶</a></h2>
<p>Data Scientists sind weder Informatiker, Mathematiker, Statistiker, oder Domainenexperten. Der perfekte Data Scientists bringt eine Kombination von allem als Fähigkeiten mit:</p>
<ul class="simple">
<li><p>Gute mathematische Fähigkeiten, insbesondere über Optimierung und Stochastik.</p></li>
<li><p>Sicher Umgang mit Methoden aus der Statistik, insbesondere Regression, statistische Tests und Inferenz.</p></li>
<li><p>Gute Programmierkenntnisse, sicherer Umgang mit Datenbanken, Datenstrukturen, parallelem Rechnen und Big Data Technologien.</p></li>
<li><p>Problemloser Wechsel zwischen den obigen Fähigkeiten und sicherer Umgang mit Technologien die in der Schnittstelle liegen, insbesondere dem maschinellen Lernen.</p></li>
<li><p>Genug Wissen über die Domäne um die Daten zu verstehen, Fragestellungen zu definieren und zu erarbeiten ob und wie diese Fragen mit Hilfe von Daten beantwortet werden können.</p></li>
</ul>
<p>Außerdem müssen Date Scientists Teamfähig sein, um mit Domänenexperten auf der einen Seite, und technischen Experten auf der anderen Seite zusammenarbeiten zu können. Die Domänenexperten helfen dem Data Scientists die Daten, Fragestellungen, und Projektziele zu verstehen. Die technischen Experten helfen bei der Umsetzung von Projekten, insbesondere bei der Operationalisierung.</p>
<p>Nicht zuletzt sollten Data Scientists zwar den notwendigen Enthusiasmus mitbringen um sich für die Arbeit mit Daten begeistern zu können, aber auch die notwendige Skepsis um die Problemstellung nach wissenschaftlichen Prinzipien anzugehen. Dies heißt insbesondere auch, dass man alles tun sollte, um auszuschließen das etwas nur aus Zufall funktioniert und rigoros überprüfen muss ob Modelle wirklich wie gewünscht funktionieren.</p>
<p>Wenn man sich dieses Fähigkeitsprofil anguckt, wird schnell klar, das die Anzahl der Personen, die alles mitbringen begrenzt ist. Microsoft Research hat sich daher mit der Fragestellung befasst, was Data Scientists im Arbeitsalltag ausmacht und welche Arten von Data Scientists es gibt <a class="footnote-reference brackets" href="#mssurvey" id="id14">14</a>. Hierbei wurden neun Arten von Data Scientists bestimmt.</p>
<ul class="simple">
<li><p><em>Polymath</em> sind die Alleskönner, die das gesamte oben beschrieben Profil erfüllen und alles von der zugrunde liegenden Mathematik bis hin zu den Big Data Infrastrukturen verstehen.</p></li>
<li><p><em>Data Evangelists</em> analysieren selbst Daten, verbreiten aber auch die Erkenntnisse und Modelle. Sie setzen sich insbesondere auch dafür ein, das aus ihren Modellen Produkte entwickelt werden.</p></li>
<li><p><em>Data Preparers</em> sammeln Daten und bereiten diese für die Analyse auf.</p></li>
<li><p><em>Data Analyzers</em> analysieren Daten, die Ihnen zur Verfügung gestellt werden.</p></li>
<li><p><em>Data Shapers</em> kombinieren die beiden vorigen rollen, das heißt sie sammeln und analysieren Daten.</p></li>
<li><p><em>Platform Builders</em> sammeln nicht nur Daten, sondern entwickeln und administrieren ganze Platformen, die zur Datensammlung und Analyse genutzt werden können.</p></li>
<li><p><em>Moonlighters 50%</em> und <em>Moonlighters 20%</em> sind Teilzeit Data Scientists, die zwar auch eine Data Science Rolle ausfüllen, aber nur als ein Bruchteil ihrer täglichen Arbeit.</p></li>
<li><p><em>Insight Actors</em> sind die Nutzer von Analyse und Modellen.</p></li>
</ul>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="gartner"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p><a class="reference external" href="https://www.gartner.com/en/information-technology/glossary/big-data">https://www.gartner.com/en/information-technology/glossary/big-data</a></p>
</dd>
<dt class="label" id="mapreducepaper"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p><a class="reference external" href="https://doi.org/10.1145/1327452.1327492">https://doi.org/10.1145/1327452.1327492</a></p>
</dd>
<dt class="label" id="sneakernet"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p><a class="reference external" href="https://en.wikipedia.org/wiki/Sneakernet">https://en.wikipedia.org/wiki/Sneakernet</a></p>
</dd>
<dt class="label" id="blackhole"><span class="brackets"><a class="fn-backref" href="#id4">4</a></span></dt>
<dd><p><a class="reference external" href="https://www.extremetech.com/extreme/289423-it-took-half-a-ton-of-hard-drives-to-store-eht-black-hole-image-data">https://www.extremetech.com/extreme/289423-it-took-half-a-ton-of-hard-drives-to-store-eht-black-hole-image-data</a></p>
</dd>
<dt class="label" id="waymo"><span class="brackets"><a class="fn-backref" href="#id5">5</a></span></dt>
<dd><p><a class="reference external" href="https://waymo.com/open/">https://waymo.com/open/</a></p>
</dd>
<dt class="label" id="apache"><span class="brackets"><a class="fn-backref" href="#id6">6</a></span></dt>
<dd><p><a class="reference external" href="https://www.apache.org/">https://www.apache.org/</a></p>
</dd>
<dt class="label" id="v"><span class="brackets"><a class="fn-backref" href="#id7">7</a></span></dt>
<dd><p><a class="reference external" href="https://www.kdnuggets.com/2017/04/42-vs-big-data-data-science.html">https://www.kdnuggets.com/2017/04/42-vs-big-data-data-science.html</a></p>
</dd>
<dt class="label" id="id15"><span class="brackets"><a class="fn-backref" href="#id8">8</a></span></dt>
<dd><p><a class="reference external" href="https://mapr.com/blog/top-10-big-data-challenges-serious-look-10-big-data-vs/">https://mapr.com/blog/top-10-big-data-challenges-serious-look-10-big-data-vs/</a></p>
</dd>
<dt class="label" id="deepblue"><span class="brackets"><a class="fn-backref" href="#id9">9</a></span></dt>
<dd><p><a class="reference external" href="https://doi.org/10.1007/978-1-4612-2260-6">https://doi.org/10.1007/978-1-4612-2260-6</a></p>
</dd>
<dt class="label" id="robots"><span class="brackets"><a class="fn-backref" href="#id10">10</a></span></dt>
<dd><p><a class="reference external" href="https://doi.org/10.1126/scirobotics.aau5872">https://doi.org/10.1126/scirobotics.aau5872</a></p>
</dd>
<dt class="label" id="jeopardy"><span class="brackets"><a class="fn-backref" href="#id11">11</a></span></dt>
<dd><p><a class="reference external" href="https://www.ibm.com/ibm/history/ibm100/us/en/icons/watson/">https://www.ibm.com/ibm/history/ibm100/us/en/icons/watson/</a></p>
</dd>
<dt class="label" id="cancer1"><span class="brackets"><a class="fn-backref" href="#id12">12</a></span></dt>
<dd><p><a class="reference external" href="https://www.ibm.com/marketplace/clinical-decision-support-oncology">https://www.ibm.com/marketplace/clinical-decision-support-oncology</a></p>
</dd>
<dt class="label" id="cancer2"><span class="brackets"><a class="fn-backref" href="#id13">13</a></span></dt>
<dd><p><a class="reference external" href="https://spectrum.ieee.org/biomedical/diagnostics/how-ibm-watson-overpromised-and-underdelivered-on-ai-health-care">https://spectrum.ieee.org/biomedical/diagnostics/how-ibm-watson-overpromised-and-underdelivered-on-ai-health-care</a></p>
</dd>
<dt class="label" id="mssurvey"><span class="brackets"><a class="fn-backref" href="#id14">14</a></span></dt>
<dd><p><a class="reference external" href="https://doi.org/10.1109/TSE.2017.2754374">https://doi.org/10.1109/TSE.2017.2754374</a></p>
</dd>
</dl>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../vorwort.html" title="previous page">Vorwort</a>
    <a class='right-next' id="next-link" href="kapitel_02.html" title="next page"><span class="section-number">2. </span>Der Prozess von Data Science Projekten</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Steffen Herbold<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>