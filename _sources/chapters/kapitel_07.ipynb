{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "declared-shade",
   "metadata": {},
   "source": [
    "# Klassifikation\n",
    "\n",
    "## Überblick\n",
    "\n",
    "Bei der Klassifikation geht es darum Kategorien zu Objekten zuzuweisen. Betrachten wir das Beispiel in {numref}`fig-class-example`. Das obere Bild zeigt einen Wal vor einem Eisberg. Das unsere Bild zeigt einen Bär in einem Wald. Beides erkennt man als menschlicher Betrachter instinktiv ohne darüber nachzudenken. Das Ziel der Klassifikation ist es diese Kategorisierung von Objekten automatisch durch eine Algorithmus durchführen zu lassen. Eine wichtige Einschränkung gegebenüber unserer menschlichen Kategoriesierung ist, das wir nur mit festen und im vorfeld festgelegten Kategorien arbeiten können Im Beispiel in {numref}`fig-class-example` könnten diese Kategorien zum Beispiel \"Wal\", \"Bär\" und \"Sonstiges\" sein. Die Klassifikationsaufgabe wäre dann die Zuweisung einer dieser drei Kategorien zu den Bilden. Die Kategorien, in die die Objekte eingeteilt werden, nennt man auch *Klassen*. \n",
    "\n",
    "```{figure} images/classification_example_german.png\n",
    "---\n",
    "width: 600px\n",
    "name: fig-class-example\n",
    "---\n",
    "Zuweisung der Kategorien Wal und Bär zu Bildern. \n",
    "```\n",
    "\n",
    "Etwas abstrakter können wir uns die Klassifikation wie in Abbildung {numref}`fig-class-abstract` vorstellen. Wir haben also Objekte für die wir ein *Konzept* kennen. Wenden wir unser Konzept auf die Objekte an, bekammen wir die Einteilung in Klassen. Wir kennen also ein Konzept das Wale beschreibt, welches wir auf das Bild wenden können um die Klasse zu bestimmen. \n",
    "\n",
    "```{figure} images/classification_concept_german.png\n",
    "---\n",
    "width: 600px\n",
    "name: fig-class-abstract\n",
    "---\n",
    "Abstraktes Konzept der Klassifikation\n",
    "```\n",
    "\n",
    "Das Ziel von Klassifikationsalgorithmen ist es eine *Hypothese* aus den Daten abzuleiten, mit der man die Klasse von Objekten anhand der Merkmale bestimmen kann. Als Beispiel betrachten wir das Bild des Wals durch die Merkmale ({numref}`fig-hypothesis`). Über diese Merkmale könnte man auf folgende Hypothese kommen: *Objekte mit Flossen, die eine ovale Form haben, welche oben schwarz und unten weiß sind und die sich vor einem blauen Hintergrund befinden, sind Wale*. Diese Hypothese mag zwar nicht in jedem Fall richtig sein, sie ist aber eine relativ gute Beschreibung, mit der man viele Wale (bzw. Orcas) richtig erkennt. Fehler würde man zum Beispiel machen, wenn es ein U-Boot mit einer ähnlichen Farbwal gäbe. Die Art der Hypothese, zum Beispiel ob es sich um einen logischen Ausdruck oder eine beliebige mathematische Funktion handelt, hängt von der Wal des Algorithmus ab. Die Hypothese selbst wird vom Lernalgorithmus automatisch aus den Daten bestimmt. \n",
    "\n",
    "```{figure} images/hypothesis_german.png\n",
    "---\n",
    "width: 600px\n",
    "name: fig-hypothesis\n",
    "---\n",
    "Abstraktes Konzept der Klassifikation\n",
    "```\n",
    "\n",
    "Formal haben wir eine Menge von Objekten $O = \\{object_1, object_2, ...\\}$ welche möglicherweise unendliche viele Elemente enthält. Außerdem haben wir eine Repräsentation der Objekte als Instanzen im Merkmalsraum $\\mathcal{F} = \\{\\phi(o): o \\in O\\}$ und eine endliche Anzahl von Klassen $C = \\{class_1, ..., class_n\\}$. Die Klassifikation wird durch ein *Zielkonzept* (engl. *target concept*) beschrieben, welches die Objekte auf ihre Klassen abbildet, also\n",
    "\n",
    "$$h^*: O \\to C.$$\n",
    " \n",
    "Das Zielkonzept ist die wahre Klasse der Objekte, also eine perfekte Zuweisung von Objekten zu Klassen. Im normalfall ist keine mathematische Beschreibung des Zielkonzepts bekannt. Es gibt zum Beispiel keine mathematische Beschreibung zur Klassifikation von Bildern in Walbilder und Bärenbilder. Die *Hypothese* bildet die Merkmale auf die Klassen ab, also\n",
    "\n",
    "$$h: \\mathca{F} \\to C.$$\n",
    "\n",
    "Die Hypothese wird vom Klassifikationsalgorithmus so bestimmt, dass sie eine gute Approximation des Zielkonzept ist, also\n",
    "\n",
    "$$h^*(o) \\approx h(\\phi(o)).$$\n",
    "\n",
    "Eine Variante der Klassifikation ist die Berechnung von *Scores* für jede Klasse $c \\in C$. In diesem Fall haben wir Scoring-Funktionen\n",
    "\n",
    "$$h_c^': \\mathcal{F} \\to \\mathbb{R}$$\n",
    "\n",
    "für jede Klasse. Die Scores sind ähnlich zum Soft Clustering: Anstatt das wir alle Instanzen genau einer Klasse zuweisen, bestimmen wir eine Wert für jede Klasse, den wir dann für die Entscheidungsfindung nutzen können. Im Normalfall wird dann die Klasse zugewiesen, die den höchsten Score hat. Wir haben also\n",
    "\n",
    "$$h(x) = \\arg\\max_{c \\in C} h_c'(x)$$ \n",
    "\n",
    "für $x \\in \\mathcal{F}$. Oft handelt es sich bei den Scores um Wahrscheinlichkeitsverteilungen, so dass der Score für jeder Klasse im Intervall $[0,1]$ liegt und die Summe der Scores aller Klasse 1 ergibt. In diesem Fall geben die Scores die Wahrscheinlichkeit an, dass ein Objekt zu einer bestimmten Klasse gehört. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-adobe",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "### Binary Classification and Thresholds\n",
    "\n",
    "A special case of classification problems is where we have exactly two classes. While this is a strong restriction, there are many problems that can be solved using binary classification. For example, the prediction if a borrower will pay back money, the prediction if a transaction is fraudulent, or the prediction of whether an email is spam or not. \n",
    "\n",
    "For binary classification, we usually say that one class is *positive* and the other class is *negative*. Thus, we have exactly two classes. If we have only two classes $C = \\{positive, negative\\}$ and the scores, we can calculate the score of one class based on the score of the other class, in case the scores are a probability distribution, i.e., \n",
    "\n",
    "$$h_{negative}'(x) = 1-h_{positive}'(x)$$\n",
    "\n",
    "because the sum of the probabilities is one. Because it is sufficient to use the scoring function for the $positive$, we use the notation $h'(x) = h_{positive}$ for binary classification. In this case, we can also use a *threshold* $t \\in [0,1]$ to determine the classes from the scoring function instead of just taking the class with the highest score. If $h'(x) \\geq t$, $x$ is positive, if the score is less than the threshold it is negative, i.e., \n",
    "\n",
    "$$h_t(x) = \\begin{cases}\\text{positive} & \\text{if}~h'(x) \\geq t \\\\ \\text{negative} & \\text{if}~h' < t\\end{cases}$$\n",
    "\n",
    "Why thresholds and scoring functions are important for classification is best demonstrated through an example. The histogram below shows the scores of instances of a spam detection simulation where positive means that an email is spam. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
