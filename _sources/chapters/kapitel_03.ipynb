{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solar-liechtenstein",
   "metadata": {},
   "source": [
    "# Erkunden der Daten\n",
    "\n",
    "In diesem Kapitel befassen wir uns mit Methoden, die sie einsetzen können um ein Verständnis der Daten zu bekommen. Wenn sie innerhalb eines Projektes anfangen mit einem ihnen bisher unbekannten Datensatz zu arbeiten, müssen sie diese Daten erstmal *lernen*. Das heißt das Sie die Struktur, den Umfang (z.B. Größe und Anzahl von Datenpunkten), sowie den Wertebereich der Daten lernen müssen. Eventuell wird auch ein Verständnis der Datenquellen benötigt, wenn sie die Richtigkeit und Zuverlässigkeit der Daten relevant ist oder sie Gründe für unvollstände Daten näher beleuchten wollen. \n",
    "\n",
    "Es gibt sehr viele Methoden, die man zur Erkundung von Daten einsetzen kann. Die Erkundung selbst ist ein durch Werkzeuge unterstützer interaktiver Prozess, wobei es üblich ist verschiede Werkzeuge zu benutzen, basierend auf dem Aspekt den man aktuell erkunden möchte. Im Folgenden gehen wir einige wichtige Werkzeuge durch, die Ihnen helfen Daten zu verstehen. \n",
    "\n",
    "## Texteditoren und die Kommandozeile\n",
    "\n",
    "Bereits sehr einfache Werkzeuge können ihnen helfen, die Daten zu verstehen. Texteditoren und einfache Kommandozeilenbefehle wie `head`, `more`, und `less` ermöglichen es sich den Inhalt Textdateien direkt anzusehen. Hierdurch kann man beliebige Daten, die nicht im Binärformat vorliegen, inspizieren. Das ist durchaus häufig der Fall, zum Beispiel bei *Comma-Separated Values* (CSV), der *eXtensible Markup Language* (XML), oder der *JavaScript Object Notation* (JSON). Wir könnten uns zum Beispiel direkt den Quelltext dieses Kapitels angucken, um das Format der Daten, die in Jupyter Notebooks gespeichert werden, zu verstehen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "declared-processing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"cells\": [\n",
      "  {\n",
      "   \"cell_type\": \"markdown\",\n",
      "   \"id\": \"empty-lender\",\n",
      "   \"metadata\": {},\n",
      "   \"source\": [\n",
      "    \"# Erkunden der Daten\\n\",\n",
      "    \"\\n\",\n",
      "    \"In diesem Kapitel befassen wir uns mit Methoden, die sie einsetzen können um ein Verständnis der Daten zu bekommen. Wenn sie innerhalb eines Projektes anfangen mit einem ihnen bisher unbekannten Datensatz zu arbeiten, müssen sie diese Daten erstmal *lernen*. Das heißt das Sie die Struktur, den Umfang (z.B. Größe und Anzahl von Datenpunkten), sowie den Wertebereich der Daten lernen müssen. Eventuell wird auch ein Verständnis der Datenquellen benötigt, wenn sie die Richtigkeit und Zuverlässigkeit der Daten relevant ist oder sie Gründe für unvollstände Daten näher beleuchten wollen. \\n\",\n"
     ]
    }
   ],
   "source": [
    "!head kapitel_03.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-archive",
   "metadata": {},
   "source": [
    "Durch diesen einfachen Befehl, der nur die ersten Zeilen der Datei anzeigt, können wir viel über die Daten lernen: Die Daten sind im JSON Format als Liste von Zellen (`cells`) gespeichert. Für jede Zelle werden der Typ, eine Identifier, eventuelle Metadaten, sowie der Quelltext der Zelle als Liste gespeichert, wobei jeder Listeneintrag eine Zeile des Quelltextes ist. All das, nur mit einem einfachen Kommandozeilenbefehl. \n",
    "\n",
    "> **Bemerkung:**\n",
    ">\n",
    "> Man kann durch ein Ausrufezeichen als Präfix beliebige Kommandozeilenbefehle (z.B. bash) direkt aus einem Jupyter Notebook aufrufen. Daher ist `head` in einem Juypter Notebook äquivalent zur Eingabe von `head`direkt in der Kommandozeile. Welche Befehle zur Verfügung stehen, hängt von der Ausführungsumgebung ab. Weil die Kommandozeile von Windows den Befehl `head` nicht kennt, würde dies zum Beispiel eventuell nicht funktionieren. \n",
    "\n",
    "Dies ist natürlich nur eine Möglichkeit sich mit der Art wie Jupyter Notebooks Daten speichern zu betrachten. Und wie die meisten sehr einfachen Lösungen, gibt es natürlich auch schwächen. Es ist zum Beispiel nicht klar, ob es noch weitere Informationen gibt, die für Zellen gespeichert werden könnten, da der betrachtete Auszug eventuell nicht alle Möglichkeiten des Datenformats ausschöpft. Daher ist es auch wichtig, dass die Metadaten betrachtet werden, in diesem Fall das Dokumentation des Datenformats [^jupyterformat]. Dort findet man zum Bespiel raus, das es noch weitere Felder gibt, wie zum Beispiel das Feld `nbformat` um die Version des Datenformats anzuzeigen. Eine gute Dokumentation der Metadaten beschreibt das Datenformat vollständig, das heißt welche Felder es gibt, welche Informationen in einem Feld gespeichert werden, und wie die Felder zusammenhängen. \n",
    "\n",
    "Die Metadaten sind nicht notwendigerweise auf die Beschreibung der Daten selbst beschränkt. Es könnten zum Beispiel auch Links zu weiterführenden Informationen zur Verfügung gestellt werden. Außerdem könnten auch die Datenquellen beschrieben sein. Was man in den Metadaten überlicherweise nicht vorfindet ist eine Beschreibung der Werte, welche die Daten in einem Datensatz haben. Hier findet man höchstens Beispiele, die veranschaulichen welche Werte angenommen werden können. Dies ist ein Nachteil gegenüber der direkten Betrachtung der Daten, wobei die Erkenntisse über die Daten Werte der Daten, die man mit Hilfe eines Texteditors bekommen kann ebenfalls stark limitiert ist, gerade bei großen Datenmengen. Hierfür sind die Statistiken und Visualisierungen, die wir im Folgenden betrachten, deutlich besser geeignet. \n",
    "\n",
    "## Deskriptive Statistik\n",
    "\n",
    "Die *deskriptive* Statistiik beschäftigt sich mit der Beschreibung von Eigenschaften eines Datensatzes durch einzelne, häufig numerische, Werte. Deskriptive Statistiken sollen nicht mit *induktiver* Statistik verwechselt werden, bei der es darum geht Eigenschaften von Daten vorherzusagen. Entsprechend sollte man nicht annehmen, dass deskriptive Statistiken für zuverlässige Vorhersagen von zukünftigen Werten geeignet sind. \n",
    "\n",
    "In diesem Kapitel betrachten wir die folgenden deskriptiven Statistiken: \n",
    "- Die *Lage* der Daten (engl. *central tendency*), durch das *artithmische Mittel*, den *Median*, und den *Modus*. \n",
    "- Die Variabilität der Daten, durch die *Standardabweichung*, den Interquartilsabstand* (IQR), und den *Median der absoluten Abweichung vom Median* (MAD). \n",
    "- Die Datenbereich (engl. *range*), durch das *Minimum* und *Maximum*. \n",
    "\n",
    "Es gibt noch viele weitere deskriptive Statistiken für die obigen Eigenschaften, die wir in diesem Kapitel nicht betrachten, zum Beispiel das harmonische Mittel für die Lage. Weiterhin gibt es noch weitere Eigenschaften, die sich durch deskriptive Statistiken erfassen lassen, zum Beispiel die *Form* (engl. *shape*) der Daten durch die *Kurtose* (Wölbung) und die *Schiefe* (engl. *skewness*). Diese gehen jedoch über die Betrachtungen dieses Kapitels hinaus und werden häufig auch nicht benötigt, insbesondere wenn man deskriptive Statistiken zusammen mit Visualisierungen benutzt. \n",
    "\n",
    "Im folgenden Benutzen wir die Notation $x = (x_1, ..., x_n)$ mit $x_1, ..., x_n \\in \\mathbb{R}$. Der Wert $x$ beschreibt also einen Vektor von reellen Zahlen. Wenn es sich bei $x$ um eine Teilmenge der möglichen Daten handelt, nennt man $x$ auch *Stichprobe* (engl. *sample*). Der Einfachheit halber können Sie sich $x$ auch einfach als Menge von Zahlen vorstellen. Dies ist zwar für die Vorstellung of einfacher, jedoch formal nicht korrekt, da Mengen nicht das gleiche Element mehrfach enthalten können, Datensätze jedoch schon.\n",
    "\n",
    "### Lagemaße\n",
    "\n",
    "Die Lage der Daten ist ein wichtiges statistisches Merkmal welches den *typischen Wert* im Zentrum der Daten beschreibt. Dies bedeutet nicht, das viele Datenpunkte exakt diesen Wert haben oder das man in der Zukunft erwarten könnte häufig diesen Wert zu beobachten. Stattdessen markiert die Lage die \"Mitte\" der Daten. Wenn Sie sich die Daten als Stadt vorstellen, markiert die Lage also nur den Mittelpunkt der Stadt. Das heißt jedoch nicht, dass dort besonders viele Häuser stehen. \n",
    "\n",
    "Es gibt verschiedene Wege die Lage von Daten zu definieren. Das *arithmetische Mittel* ist definiert als\n",
    "$$mean(x) = \\frac{1}{n}\\sum_{i=1}^{n} x_i, x_i \\in \\mathbb{R},$$\n",
    "also die Summe der Datenpunkte geteilt durch ihre Anzahl. Häufig spricht man auch einfach vom *Mittelwert* der Daten (engl. *mean*). Das arithmische Mittel ist eine gute Beschreibung der Lage, wenn die Daten normalverteilt oder gleichverteilt sind. Im Allgemeinen sollte man das arithmeische Mittel nur verwenden, wenn zwei Eigenschaften erfüllt sind:\n",
    "\n",
    "1. Es gibt keine \"lücken\" in den Daten, also größere Bereiche in denen keine Werte liegen. Dies bedeutet insbesondere auch, dass die Daten keine Ausreißer haben sollten. \n",
    "2. Die Daten sind symmetrisch um das artithmetische Mittel verteilt, das heißt das die Verteilung links und rechts des artihmetischen Mittels ist in etwa gleich sein sollten.\n",
    "\n",
    "Wenn diese Eigenschaften nicht erfüllt sind, sollte man das artithmetische Mittel nicht verwenden, da der Wert eventuell die Lage nicht gut beschreibt. Statistische Methoden, die derartige Annahmen an die Verteilung von Daten machen nennt man auch *parametrische* Statistiken. Wir werden uns später noch anhand von [Anscombes Quartet](#anscombes-quartet) sehen, wie die Werte von Statistiken irreführend sein können.\n",
    "\n",
    "Eine alternative zum arithmetischen Mittel ist der *Median*, der definiert ist als\n",
    "$$median(x) = \\begin{cases}\\bar{x}_{m} & \\text{wenn}~n~\\text{ungerade ist mit}~m=\\frac{n+1}{2} \\\\ \\frac{1}{2}(\\bar{x}_{m}+\\bar{x}_{m+1}) & \\text{wenn}~n~\\text{gerade ist mit}~m=\\frac{n}{2},\\end{cases}$$\n",
    "wobei $\\bar{x}$ eine nach der größe sortierter Vektor der Werte von $x$ ist. Entsprechend ist der Median wortwörtlich in der Mitte der der Daten: 50% der Daten sind kleiner oder gleich dem Median und 50% sind größer oder gleich dem Median. Im Gegensatz zum arithmetischen Mittel ist der Median eine *nicht parametrische* Statistik. Das bedeutet das der Median unabhängig von der Verteilung eingesetzt werden kann, zum Beispiel wenn die Annahmen an das arithmetische Mittel nicht erfüllt sind. Insbesondere ist der Median robust gegen Ausreißer, kann also nicht durch wenige besonders hohe oder niedrige Werte beeinflusst werden. \n",
    "\n",
    "Dies kann man sich auch an einem einfachen Beispiel verdeutlichen. Zuerst betrachten wir das arithmetische Mittel und den Median für Daten, bei denen die Annahmen des arithmetischen Mittels erfüllt sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "juvenile-cursor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:   7.500909090909091\n",
      "median: 7.58\n"
     ]
    }
   ],
   "source": [
    "import statistics  # we use the statistics from the Python standard library\n",
    "\n",
    "data = [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68]\n",
    "\n",
    "print('mean:  ', statistics.mean(data))\n",
    "print('median:', statistics.median(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-tracker",
   "metadata": {},
   "source": [
    "In diesem Beispiel sind die Werte vom Median und vom arithmetischen Mittel ähnlich und beide sind gut geeignet und die Lage zu beschreiben. Jetzt erweitern wir die Daten um einen einzelnen Ausreißer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "specific-incident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:   15.209166666666667\n",
      "median: 7.81\n"
     ]
    }
   ],
   "source": [
    "data.append(100)\n",
    "print('mean:  ', statistics.mean(data))\n",
    "print('median:', statistics.median(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-testimony",
   "metadata": {},
   "source": [
    "Durch den Ausreißer wird das arithmetische Mittel start beeinflusst, so dass es jetzt deutlich höher ist. Es ist sogar höher alls alle Datenpunkte, die wir ursprünglich betrachtet haben. Das ist offensichtlich keine gute Beschreibung der Mitte der Daten. Im Vergleich dazu, hat sich der Median kaum verändert und ist nur zum nächsthöheren Wert der sortieren Liste gesprungen. \n",
    "\n",
    "Möglicherweise fragen Sie sich jetzt, warum man überhaupt das arithmetische Mittel verwenden sollte, wenn der Median scheinbar aufgrund seiner Robustheit überlegen ist. Die Gründe hierfür kommen aus der Stochastik. Das arithmetische Mittel ist ein enger verwandt mit dem Erwartungswert von Zufallfsvariablen. Die Normalverteilung kann man vollständig durch den Mittelwert und die Standardabweichung beschreiben. Hieraus folgt, dass das arithmetische Mittel für die Normalverteilung der Beweisbar bestmögliche Schätzer für die Mitte der Daten ist. Trotzdem ist es ratsam den Median zu verwenden, wenn Sie die Verteilung der Daten nicht kennen oder Sie befürchten das es vielleicht Ausreißer gibt.\n",
    "\n",
    "Das arithmetische Mittel und der Median sind nur für numerische Daten definiert. Es gibt jedoch auch nicht-numerische Daten. Die größe von Kleidungsstücken wird häufig in den Kategorien \"Small\", \"Medium\", und \"Large\" angegeben. Man spricht hierbei von kategorischen Daten (TODO ref Kapitel 4). Der *Modus* der Daten kann benutzt werden um die Lage von kategorischen Daten zu bestimmen. Der Modus ist definiert als der Wert, den man am häufigsten in einer Stichprobe $x$ beobachtet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "structural-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode: medium\n"
     ]
    }
   ],
   "source": [
    "data = ['small', 'medium', 'small', 'large', 'large', 'medium', 'medium']\n",
    "print('mode:', statistics.mode(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-kelly",
   "metadata": {},
   "source": [
    "Bitte beachten Sie, dass der Modus zwar gut für kategorische Daten (und manchmal auch für diskret Verteilte numerische Daten) geeignet ist, aber irreführend sein kann wenn die Daten *Bimodal* oder *Multimodal*, also wenn es mehrere \"Mittelpunkte\" gibt was sich dadurch äußert das mehrere Werte besonders häufig auftreten. Im Extremfall sind die kategorien gleichverteilt, also man hat gleich viele Beobachtungen pro Kategorie. Da jede Kategorie die gleiche Wahrscheinlichkeit hat, ist der Modus zufällig. Außerdem sollte man den Modus nicht für kontinuierliche numerische Daten benutzen, da es hier sehr unwahrscheinlich ist mehrfach den exakt gleichen Wert zu beobachten. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-booking",
   "metadata": {},
   "source": [
    "[^jupyterformat]: https://nbformat.readthedocs.io/en/latest/format_description.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-mechanism",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "\n",
    "### Variability\n",
    "\n",
    "The variability measures how far the data is spread out. A small variability means that most data is close to the central tendency of the data. A high variability means that the data is spread out over a large range. \n",
    "\n",
    "The most common measure for the variability is the *standard deviation*, which is defined as\n",
    "\n",
    "$$sd(x) = \\sqrt{\\frac{\\sum_{i=1}^n (x_i-mean(x))^2}{n-1}}.$$\n",
    "\n",
    "The standard deviation is the square root of the arithmetic mean of the difference from the arithmetic mean, except that the division is by $n-1$ instead of $n$. This is due to something called *degrees of freedom*, which we do not discuss here further. The standard deviation tells us how much deviation from the mean value we can expect. The standard deviation works well as a measure for the variability, when the mean value is a suitable representation for the central tendency. This means that the standard deviation is also a *parametric* measure for the variability, that can also be misleading.\n",
    "\n",
    "Same as the median is the non-parametric counterpart to the arithmetic mean, there are also non-parametric statistics for the variability. The *interquartile range* is defined as\n",
    "\n",
    "$$IQR(X) = Q_{upper}-Q_{lower}$$\n",
    "\n",
    "where $Q_{upper}$ is the upper quartile and $Q_{lower}$ is the lower quartile. The upper quartile and lower quartile are defined analogously to the median, but with 75% and 25% of the data. This means that for the upper quartile, 75% of the data are less than or equal to $Q_{upper}$ and 25% are greater than or equal to $Q_{upper}$. For the lower quartile, 25% of the data are less than or equal to $Q_{lower}$ and 75% of the the data are greater than or equal to $Q_{lower}$. It follows that at least 50% of the data is within the interquartile range. \n",
    "\n",
    "In general, you should not use the standard deviation, when you use the median. Below is the example we already used to demonstrate that the arithmetic mean is not robust with respect to outliers. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
